-----------------------------------------------------------------------------
| CHAPTER 6 - STORAGE                                                       |
-----------------------------------------------------------------------------

- Storage

    - Storage systems underpin all the major stages (ingegestion, transformation, and serving) of
        the DE lifecycle.


    - Storage Abstractions (Abstractions of storage systems)

        - Data Lake
        - Data Lakehouse
        - Data Platform
        - Cloud Data Warehouse


    - Storage Systems (Abstractions of raw ingredients)

        - RDBMS
        - HDFS
        - Redis
        - Object Storage
        - Kafka


    - Raw Ingredients

        - HDD
        - SDD
        - RAM
        - Networking
        - Serialization
        - Compression
        - CPU



- Magnetic Disk Drives

    - Developed by IBM in the 1950s.  The first commercial magnetic drive, the IBM 350, had a capacity
        of 3.75 MB.


    - Magnetic disks utilize spinning platters coated with a ferromagnetic film. This film is
        magnetized by a read/write head during write operations to physically encode binary data. 

      The read/write head detects the magnetic field and outputs a bitstream during read operations.


    - Magnetic disk drives (HDDs) still form the backbone of bulk data storage systems because they are 
        significantly cheaper than SSDs.  However, SSDs dramatically outperform them.


    - Currently, HDD drives cost ~ $0.03 per GB of storage.  Drives as large as 20 TB are commercially
        available.


    - HDDs have seen a lot of innovations and improvements, but are constrained by physical limits:

        1. 'Disk transfer speed', the rate at which data can be read and written, grows linearly while
             capacity grows areally (GB per in**2).  Current data center drives support maximum
             transfer speeds of 300 MB/s.

        2. 'Seek time' is limited by the ability of the drive to physically relocate the read/write
             heads to the appropriate track on the disk.

        3. 'Rotational latency' is how long the disk must wait for the desired sector to rotate under
             read/write heads.  Commercial drives typically spin at 7200 rpm.

        4. IOPs is another limitation, crucial for transactional databases.  A magnetic drive supports
             50-100 IOPs.


    - Magnetic disks can sustain extremely high data rates through parallelism.  For instance, object
        storage distributes data across thousands of drives in clusters.

      In this case, data transfer rates are limited by network performance rather than disk transfer
        rate.  This makes network components and CPUs crucial also.



- Solid-State Drives

    - SSDs store data as charges in flash memory cells, which eliminates the mechanical components of
        magnetic drives.

        - Look up random data in less than 0.1 ms

        - Commercial drives have ransfer rates of many GB/s and tens of thousands of IOPs


    - SSDs have revolutionized transactional databases, and are now standard for commercial OLTP 
        systems.  Allow RDBMS's to handle thousands of transactions per second.


    - For cost reasons, magenetic drives are still the standard for high-scale analytics data storage.
        SSDs can be used to cache frequently accessed data.



- RAM

    - RAM, also just called 'memory' has specific characteristics:

        - Attached to a CPU and mapped into the CPU address space

        - Stores the code the CPUs execute and the data it directly processes

        - Volatile

        - DDR5 (the latest standard) offers data retrieval latency on the order of 100 ns (roughly
            1,000x faster than SSDs)

        - A typical CPU can support 100 GB/s bandwidth to attached memory and millions of IOPs

        - Is much more expensive than SSDs (~ $10/GB)

        - Is limited in the amount of RAM attached to an individual CPU and memory controller.
            High-memory servers typically utilize many interconnected CPUs on one board, each with a 
            block of attached RAM.

        - Significantly slower than CPU cache


    - When we talk about system memory, we mean DRAM (Dynamic RAM), a high-density and low-cost form
        of memory.  DRAM stores data as charges in capacitors.  These capacitors leak over time, so
        data must be frequently refreshed to avoid data loss.

      Other forms of memory, such as static RAM, are used in specialized applications such as CPU
        caches.


    - Current CPUs use von Neumann architecture, with code and data stored together in the same memory
        space.


    - RAM is used by data systems for caching, data processing, and indexing.  When using it, we must
        always remember it is volatile and a power outage could lead to data loss.



- Networking and CPU

    - In distributed systems, network performance is often the bottleneck.  While storage standards such
        as RAID parallelize on a single server, cloud object storage clusters operate both within and
        across multiple data centers.


    - CPUs handle the details of servicing requests, aggregating reads, and distributing writes.
        Storage becomes a web app with an API, backend service components, and load balancing.



- Serialization

    - 'Serialization' is the process of flattening and packing data into a standard format the a reader
        will be able to decode.  It is a critical element in database design, and affects network
        performance, CPU overhead, query latency, and more.


    - Row-based formats such as XML, JSON, and CSV are the most popular formats.


    - A serialization algorithm has logic for handling types, imposes rules on data structure, and
        checks for cyclic references.



- Compression

    - Highly efficient compression has 3 main advantages in storage systems.

        1. The data is smaller and takes up less space on disk

        2. Increases the practical scan speed per disk

        3. Network performance


    - Compression and decompression data have costs, though.  Extra time and resources are needed to 
        read or write data.



- Caching

    - The core idea of caching is to store frequently or recently accessed data in a fast access layer. 

      The faster the cache, the higher the cost and the less storage space available. Less frequently 
        accessed data is stored in cheaper, slower storage.


    - Here is a cache hierarchy (note that a microsecond is 1,000 nanoseconds, and a millisecond is 
        1,000 microseconds):

        Storage type     Data fetch latency     Bandwidth                     Price
        ----------------------------------------------------------------------------------
        CPU cache        1 nanosecond           1 TB/s
        
        RAM              0.1 microseconds       100 GB/s                      $10/GB

        SSD              0.1 milliseconds       4 GB/s                        $0.20/GB

        HDD              4 milliseconds         300 MB/s                      $0.03/GB
        
        Object storage   100 milliseconds       3 GB/s per instance           $0.02/GB per month

        Archival storage 12 hours               Same as object storage once   $0.004/GB per month
                                                  data is available



- Single Machine vs Distributed Storage

    - When data is distributed across multiple servers, it is known as 'distributed storage'.
        Distributed storage coordinates the activities of multiple servers.


    - Distributed storage is used for both redundancy and scalability.


    - Consistency issues arise when distributed storage is used.



- Eventual vs Strong Consistency

    - Since it takes time to replicate changes across the nodes of a system, a balance exists between
        getting current data and getting 'sort of current' data in a distributed database.


    - The BASE model is defined as:

        Basically Available = Consistent data is available most of the time

        Soft State = The state of a transaction is fuzzy, it is uncertain whether committed or not

        Eventual Consistency = At some point, reading will return consistent values


    - DEs often make consistency decisions in 3 places:

        1. Choosing the DB technology
        2. Configuration parameters for the DB
        3. On a per-query basis



- File Storage

    - A 'file' is a data entity with specific read, write, and reference characteristics used by 
        software and operating systems. It has these characteristics:

        - Finite length = a file is a finite-length stream of bytes

        - Append operations = can append bytes to the file up to the limits of the host storage system

        - Random access = can read from or write to any location in the file


    - File storage systems organize files into a directory tree.  To avoid hard-coding file paths,
        it is usually better to use object storage as an intermediary.

      Manual, low-level file handling processes are best left to one-time ingestion steps or 
        exploratory stages of the pipeline.


    - The most familiar types of file storage are OS-managed filesystems on a local partition of an
        SSD or magnetic disk.  NTFS (Windows) and ext4 (Linux) are the most popular.  The OS handles
        the details of storing directory entities, files, and metadata.

      Local filesystems usually have read/write consistency, and OS's employ locking strategies to
        management concurrent attempts to write a file.


    - 'Network-Attached Storage (NAS)' systems provide a file storage system to clients over a network.
        Servers often ship with built-in NAS-dedicated hardware.

      While there are performance penalties to accessing a filesystem over a network, the advantages
        include redundancy, reliability, storage pooling, and file sharing.


    - Cloud filesystem services provide a fully-managed filesystem to use with multiple VMs and
        applications.  This is different from standard storage attached to VMs (block storage managed
        by the VM's OS).  They behave mostly like a NAS.  AWS EFS is a popular example.



- Block Storage

    - Fundamentally, 'block storage' is the type of raw storage provided by HDDs and SSDs.  A 'block'
        is the smallest addressable unit of data supported by a disk (512 B on older disks, 4096 B
        on modern disks).  Blocks typically contain extra bits for error detection/correction and
        other metadata.


    - In the cloud, virtualized block storage is the standard for VMs.  These block storage abstractions
        allow fine control of storage size, scalability, and data durability beyond that offered by raw 
        disks.


    - Transactional database systems usually access disks at a block level to lay out data for optimal
        performance.


    - Block storage also remains the default option for OS boot disks on cloud VMs.


    - 'RAID (Redudant Array of Independent Disks)' simultaneously controls multiple disks to improve
        data durability, enhance performance, and combine capacity from multiple drives.  An array
        can appear to an OS as a single block device.  Many different schemes are available to fine-tune
        the bandwidth vs fault tolerance balance.


    - 'SANs (Storage Area Networks)' provide virtualized block storage devices over a network, typically
        from a storage pool.  They can allow for fine-grained scaling, performance, availability, and
        durability.  You may encounter them either on-premises or in the cloud.



- Cloud Virtualized Block Storage

    - 'Cloud Virtualized Block Storage' solutions are similar to SANs, but free engineers from dealing
        with SAN clusters and networking details.

      
    - AWS EBS is a popular implementation.  It is the default storage for EC2 VMs.


    - EBS volumes store data separate from the instance host server but in the same zone to support
        high performance and low latency.  This allows EBS volumes to persist after an EC2 instance
        is shut down, a host fails, or even when the instance is deleted.

      
    - It is also suitable for applications like databases where durability is a high priority.  Also,
        EBS replicates all data to at least 2 host machines.


    - EBS storage virtualization also suports some advanced features:

        - Can take point-in-time snapshots while the drive is in use and write them to S3
        - Snapshots after full backup are diffs
        - EBS volumes can scale to 64 TB, 250K IOPs



- Local Instance Volumes

    - Cloud providers also offer block storage volumes that are physically attached to the host server
        running a VM.  These storage volumes are generally very low cost (included with the cost of a
        VM in EC2).


    - Instance store volumes behave esentially like a disk physically attached to a server.  One key
        difference, however, is that when a VM shuts down or is deleted, the contents of locally
        attached storage are lost.  This ensures a new VM cannot read disk contents belonging to 
        another customer.


    - Locally attached disks don't support advanced features, like replication, snapshots, or other
        backup features.


    - We can still use them for lots of things, like local caches that don't need features of a service
        like EBS.  For instance, if we are running EMR on EC2 instances, we just need a job that
        consumes data from S3, stores it temporarily in the distributed filesystem across the
        instances, processes it, then writes it back to S3.
